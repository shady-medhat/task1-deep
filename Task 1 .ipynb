{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53b510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad382dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shady\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = datasets.load_boston()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Preprocess the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52d14e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 33ms/step - loss: 617.7435 - mae: 22.9538 - val_loss: 536.7724 - val_mae: 21.6078\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 576.9152 - mae: 22.0380 - val_loss: 499.4610 - val_mae: 20.7256\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 536.6027 - mae: 21.0632 - val_loss: 457.1215 - val_mae: 19.6790\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 487.5660 - mae: 19.8852 - val_loss: 405.9939 - val_mae: 18.3560\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 427.6884 - mae: 18.4059 - val_loss: 346.8580 - val_mae: 16.6903\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 360.2894 - mae: 16.6515 - val_loss: 279.7365 - val_mae: 14.8093\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 286.1128 - mae: 14.5645 - val_loss: 211.0576 - val_mae: 12.6423\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 211.2529 - mae: 12.2071 - val_loss: 147.5768 - val_mae: 10.2291\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 145.9260 - mae: 9.8159 - val_loss: 95.5869 - val_mae: 7.6603\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 97.9526 - mae: 7.8303 - val_loss: 62.4556 - val_mae: 5.7513\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 68.7532 - mae: 6.6067 - val_loss: 45.0573 - val_mae: 4.7651\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 53.1389 - mae: 5.7953 - val_loss: 36.8442 - val_mae: 4.2357\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 42.1734 - mae: 5.1347 - val_loss: 31.5100 - val_mae: 3.8961\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 33.8807 - mae: 4.5786 - val_loss: 28.7923 - val_mae: 3.7196\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.9490 - mae: 4.1873 - val_loss: 27.1373 - val_mae: 3.6453\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 25.2240 - mae: 3.8766 - val_loss: 26.2916 - val_mae: 3.5844\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 23.2015 - mae: 3.7507 - val_loss: 25.8060 - val_mae: 3.6056\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 22.3119 - mae: 3.6766 - val_loss: 25.3180 - val_mae: 3.6140\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 21.4322 - mae: 3.5833 - val_loss: 24.7332 - val_mae: 3.5562\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 20.0693 - mae: 3.4270 - val_loss: 24.6134 - val_mae: 3.4798\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 19.3194 - mae: 3.3329 - val_loss: 24.5459 - val_mae: 3.4491\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 18.8536 - mae: 3.2729 - val_loss: 24.3621 - val_mae: 3.4130\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 18.2766 - mae: 3.2235 - val_loss: 24.3779 - val_mae: 3.3958\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 17.7575 - mae: 3.1937 - val_loss: 24.2258 - val_mae: 3.3741\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 17.5729 - mae: 3.1910 - val_loss: 24.0016 - val_mae: 3.3680\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 17.0753 - mae: 3.1421 - val_loss: 23.4579 - val_mae: 3.2972\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 16.6566 - mae: 3.0890 - val_loss: 22.8396 - val_mae: 3.2513\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 16.2831 - mae: 3.0414 - val_loss: 22.4158 - val_mae: 3.2150\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 15.9658 - mae: 3.0088 - val_loss: 22.4205 - val_mae: 3.2145\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.6110 - mae: 2.9586 - val_loss: 22.2001 - val_mae: 3.1895\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 15.3429 - mae: 2.9229 - val_loss: 21.9593 - val_mae: 3.1715\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 15.0729 - mae: 2.8955 - val_loss: 21.5586 - val_mae: 3.1485\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.8163 - mae: 2.8743 - val_loss: 21.4545 - val_mae: 3.1378\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 14.4944 - mae: 2.8398 - val_loss: 21.0630 - val_mae: 3.1209\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 14.3379 - mae: 2.8196 - val_loss: 20.9711 - val_mae: 3.1458\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 14.3065 - mae: 2.8778 - val_loss: 20.8727 - val_mae: 3.1595\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.2174 - mae: 2.8858 - val_loss: 20.9946 - val_mae: 3.1498\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.6695 - mae: 2.7830 - val_loss: 20.3770 - val_mae: 3.0937\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.4065 - mae: 2.7209 - val_loss: 19.9970 - val_mae: 3.0659\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.1988 - mae: 2.6988 - val_loss: 19.9008 - val_mae: 3.0585\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 12.9562 - mae: 2.6868 - val_loss: 19.6398 - val_mae: 3.0315\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.7450 - mae: 2.6608 - val_loss: 19.0806 - val_mae: 2.9968\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.6213 - mae: 2.6258 - val_loss: 18.6642 - val_mae: 2.9882\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 12.5216 - mae: 2.6029 - val_loss: 18.4225 - val_mae: 2.9478\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 12.3642 - mae: 2.5960 - val_loss: 18.6113 - val_mae: 2.9296\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 12.1118 - mae: 2.5819 - val_loss: 18.4617 - val_mae: 2.9216\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 11.9675 - mae: 2.5638 - val_loss: 18.0745 - val_mae: 2.9001\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 11.8005 - mae: 2.5500 - val_loss: 18.1264 - val_mae: 2.9088\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 11.7291 - mae: 2.5540 - val_loss: 18.1244 - val_mae: 2.9077\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 11.5488 - mae: 2.5193 - val_loss: 17.8288 - val_mae: 2.8838\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.4267 - mae: 2.4954 - val_loss: 17.5061 - val_mae: 2.8521\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.3248 - mae: 2.4802 - val_loss: 17.4295 - val_mae: 2.8483\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.1893 - mae: 2.4616 - val_loss: 17.5855 - val_mae: 2.8562\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.0531 - mae: 2.4467 - val_loss: 17.4173 - val_mae: 2.8433\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 10.9291 - mae: 2.4385 - val_loss: 17.2231 - val_mae: 2.8337\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.9032 - mae: 2.4396 - val_loss: 17.2102 - val_mae: 2.8389\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.7565 - mae: 2.4271 - val_loss: 17.4544 - val_mae: 2.8555\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 10.6263 - mae: 2.4058 - val_loss: 16.9995 - val_mae: 2.8221\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 10.5214 - mae: 2.3882 - val_loss: 16.7657 - val_mae: 2.7977\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 10.4421 - mae: 2.3743 - val_loss: 16.8377 - val_mae: 2.7992\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 10.3295 - mae: 2.3639 - val_loss: 16.8907 - val_mae: 2.8024\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 10.2976 - mae: 2.3620 - val_loss: 16.7281 - val_mae: 2.7913\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.2493 - mae: 2.3529 - val_loss: 16.4090 - val_mae: 2.7748\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.0626 - mae: 2.3305 - val_loss: 16.2392 - val_mae: 2.7525\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.0187 - mae: 2.3229 - val_loss: 16.3851 - val_mae: 2.7671\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 9.9622 - mae: 2.3449 - val_loss: 15.7948 - val_mae: 2.7514\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.1615 - mae: 2.3958 - val_loss: 15.6922 - val_mae: 2.7239\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.8570 - mae: 2.3302 - val_loss: 16.0361 - val_mae: 2.7368\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.7150 - mae: 2.2860 - val_loss: 15.7342 - val_mae: 2.7221\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.5829 - mae: 2.2897 - val_loss: 15.6312 - val_mae: 2.7586\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.7467 - mae: 2.3303 - val_loss: 16.3166 - val_mae: 2.8179\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.7921 - mae: 2.3356 - val_loss: 15.7219 - val_mae: 2.7841\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.5894 - mae: 2.3101 - val_loss: 15.9651 - val_mae: 2.7815\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.3611 - mae: 2.2682 - val_loss: 15.7096 - val_mae: 2.7520\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.2116 - mae: 2.2419 - val_loss: 15.7673 - val_mae: 2.7527\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.2307 - mae: 2.2452 - val_loss: 15.3691 - val_mae: 2.7298\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.1476 - mae: 2.2254 - val_loss: 15.9969 - val_mae: 2.7729\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.0775 - mae: 2.2154 - val_loss: 15.3115 - val_mae: 2.6882\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.0465 - mae: 2.2055 - val_loss: 14.6162 - val_mae: 2.6466\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.8890 - mae: 2.2057 - val_loss: 15.0027 - val_mae: 2.6888\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.9175 - mae: 2.2309 - val_loss: 15.1931 - val_mae: 2.7350\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.7135 - mae: 2.1840 - val_loss: 14.4584 - val_mae: 2.6233\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.7165 - mae: 2.1706 - val_loss: 14.2914 - val_mae: 2.6152\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 8.6004 - mae: 2.1700 - val_loss: 14.7120 - val_mae: 2.6601\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.6368 - mae: 2.1707 - val_loss: 14.4808 - val_mae: 2.6357\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.5380 - mae: 2.1566 - val_loss: 14.5931 - val_mae: 2.6292\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.5308 - mae: 2.1683 - val_loss: 14.3247 - val_mae: 2.6274\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.4739 - mae: 2.1500 - val_loss: 14.4269 - val_mae: 2.6193\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.3191 - mae: 2.1247 - val_loss: 14.8216 - val_mae: 2.6532\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.3475 - mae: 2.1232 - val_loss: 14.7985 - val_mae: 2.6505\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.2657 - mae: 2.1162 - val_loss: 14.4194 - val_mae: 2.6254\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.2138 - mae: 2.1231 - val_loss: 14.3711 - val_mae: 2.6251\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.1625 - mae: 2.1089 - val_loss: 14.1298 - val_mae: 2.5996\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 8.1268 - mae: 2.1021 - val_loss: 14.2111 - val_mae: 2.6086\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.0385 - mae: 2.0868 - val_loss: 13.9558 - val_mae: 2.5787\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.0340 - mae: 2.0808 - val_loss: 13.9883 - val_mae: 2.5906\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 7.9757 - mae: 2.0724 - val_loss: 14.0229 - val_mae: 2.5929\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.8728 - mae: 2.0622 - val_loss: 14.1094 - val_mae: 2.6048\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.9297 - mae: 2.0794 - val_loss: 14.3237 - val_mae: 2.6187\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.8374 - mae: 2.0613 - val_loss: 14.3587 - val_mae: 2.6146\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1afbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 12.8213 - mae: 2.3982\n",
      "Test Loss: 12.821334838867188, Test Mean Absolute Error: 2.3981597423553467\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Test Loss: {loss}, Test Mean Absolute Error: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6c184e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
